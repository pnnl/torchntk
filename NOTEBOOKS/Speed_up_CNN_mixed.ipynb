{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2a2629",
   "metadata": {},
   "source": [
    "# The point of this is that after running into a few issues we need to rethink a few things.\n",
    "\n",
    "# 1) we can clean and make the funciton more pretty by passing a model.modules object.\n",
    "\n",
    "# 2) we can calculate the backprop more efficiently by keeping track of the second to last computation in each layer, and continuing from this place\n",
    "\n",
    "# 3) we need to be able to manipulate precisely when we use numpy vs pytorch. Pytorch GPU will likely calculate the big matrix multiplies faster, but numpy runs better manipulations and indexes on the CPU. Essentially, there are exactly L very large matrix multiplies, so lets only do that in torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b45374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import load\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from ..easy_ntk import calculate_NTK\n",
    "from einops import rearrange\n",
    "\n",
    "import time\n",
    "\n",
    "#import sys\n",
    "#from pathlib import Path\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "#from numba import njit\n",
    "#from numba.typed import List\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455c965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy CNN function-- checked that it agrees with Tensorflow.\n",
    "#need to make sure it agrees with PyTorch.\n",
    "\n",
    "\n",
    "class Conv2d():\n",
    "    def __init__(self,F,strides=1,padding=0):\n",
    "        '''\n",
    "        PYTORCH IMPLEMENTATION!!!\n",
    "        \n",
    "        this uses non-contiguous arrays, so likely a better solution exists\n",
    "        and it can't be sped up with numba and reshapes\n",
    "        \n",
    "        #given an input of x = [batches, length, channels]\n",
    "        \n",
    "        #F an input of = [channels_out, channels, kernel_size]\n",
    "        \n",
    "        #B an input of [channels_out]\n",
    "        \n",
    "        #ouputs a shape: [batches, new_length, channels_out]\n",
    "        \n",
    "        #   1. Flattens the filter to a 2-D matrix with shape\n",
    "        #      `[filter_height * filter_width * in_channels, output_channels]`.\n",
    "        #   2. Extracts image patches from the input tensor to form a *virtual*\n",
    "        #      tensor of shape `[batch, out_height, out_width, \n",
    "        #      filter_height * filter_width * in_channels]`. batch, new_length, kernel_size * in_channels\n",
    "        #   3. For each patch, right-multiplies the filter matrix and the image patch\n",
    "        #      vector.\n",
    "        '''\n",
    "        if padding < 0:\n",
    "            raise ValueError('Padding must be a non-negative int')\n",
    "        \n",
    "        self.out_filters = F.shape[0]\n",
    "        self.in_filters = F.shape[1]\n",
    "        self.kernel_height = F.shape[2]\n",
    "        self.kernel_width = F.shape[3]\n",
    "        self.F = F.T #filters array, now is [width, height, channels_in, channels_out]\n",
    "        #self.B = B #bias array\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.F = np.reshape(self.F,(-1,self.out_filters))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batches, channels_in, height, width  = np.shape(x)\n",
    "        \n",
    "        if self.padding != 0:\n",
    "            x = np.pad(x,((0,0),(0,0),(self.padding,self.padding),(self.padding,self.padding)),mode='constant',constant_values=0.0)\n",
    "    \n",
    "        new_height = int(((height + 2*self.padding - (self.kernel_height))/self.strides) + 1)\n",
    "        new_width = int(((width + 2*self.padding - (self.kernel_width))/self.strides) + 1)\n",
    "        \n",
    "        dumb_array = np.zeros((batches, new_height, new_width, self.kernel_width * self.kernel_height * channels_in),dtype=np.float32)\n",
    "        \n",
    "        for i in range(new_height):\n",
    "            for j in range(new_width):\n",
    "                dumb_array[:,i,j,:] = np.reshape(x[:,:,self.strides*i:self.strides*i+self.kernel_height, self.strides*j:self.strides*j+self.kernel_width],(batches, self.kernel_width * self.kernel_height * channels_in),order='F')\n",
    "\n",
    "        output_array = dumb_array @ self.F\n",
    "        \n",
    "        output_array = rearrange(output_array,'b h w f -> b f h w')\n",
    "\n",
    "        return output_array #+ self.B[None,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a93d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def _del_nested_attr(obj, names):\n",
    "    \"\"\"\n",
    "    Deletes the attribute specified by the given list of names.\n",
    "    For example, to delete the attribute obj.conv.weight,\n",
    "    use _del_nested_attr(obj, ['conv', 'weight'])\n",
    "    \"\"\"\n",
    "    if len(names) == 1:\n",
    "        delattr(obj, names[0])\n",
    "    else:\n",
    "        _del_nested_attr(getattr(obj, names[0]), names[1:])\n",
    "\n",
    "def _set_nested_attr(obj, names, value):\n",
    "    \"\"\"\n",
    "    Set the attribute specified by the given list of names to value.\n",
    "    For example, to set the attribute obj.conv.weight,\n",
    "    use _del_nested_attr(obj, ['conv', 'weight'], value)\n",
    "    \"\"\"\n",
    "    if len(names) == 1:\n",
    "        setattr(obj, names[0], value)\n",
    "    else:\n",
    "        _set_nested_attr(getattr(obj, names[0]), names[1:], value)\n",
    "\n",
    "def extract_weights(mod):\n",
    "    \"\"\"\n",
    "    This function removes all the Parameters from the model and\n",
    "    return them as a tuple as well as their original attribute names.\n",
    "    The weights must be re-loaded with `load_weights` before the model\n",
    "    can be used again.\n",
    "    Note that this function modifies the model in place and after this\n",
    "    call, mod.parameters() will be empty.\n",
    "    \"\"\"\n",
    "    orig_params = tuple(mod.parameters())\n",
    "    # Remove all the parameters in the model\n",
    "    names = []\n",
    "    for name, p in list(mod.named_parameters()):\n",
    "        _del_nested_attr(mod, name.split(\".\"))\n",
    "        names.append(name)\n",
    "\n",
    "    # Make params regular Tensors instead of nn.Parameter\n",
    "    params = tuple(p.detach().requires_grad_() for p in orig_params)\n",
    "    return params, names\n",
    "\n",
    "def load_weights(mod, names, params):\n",
    "    \"\"\"\n",
    "    Reload a set of weights so that `mod` can be used again to perform a forward pass.\n",
    "    Note that the `params` are regular Tensors (that can have history) and so are left\n",
    "    as Tensors. This means that mod.parameters() will still be empty after this call.\n",
    "    \"\"\"\n",
    "    for name, p in zip(names, params):\n",
    "        _set_nested_attr(mod, name.split(\".\"), p)\n",
    "        \n",
    "def calculate_NTK(model,x,device='cpu',MODE='samples'):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        model: torch.nn.Module \n",
    "        x: torch.Tensor\n",
    "        device: 'cpu',\n",
    "        MODE: 'minima'\n",
    "    \n",
    "    OUTPUTS:\n",
    "        NTK: torch.Tensor\n",
    "    \n",
    "    Calculates the NTK for a model, p_dict a state dictionary, and x, a single tensor fed into the model\n",
    "    \n",
    "    The NTK is the grammian of the Jacobian of the model output to w.r.t. the weights of the model\n",
    "    \n",
    "    This function will output the NTK such that the minima matrix size is used. If the Jacobian is an NxM\n",
    "    matrix, then the NTK is formulated so that if N < M; NTK is NxN. If M<N, then NTK is MxM.\n",
    "    \n",
    "    #EXAMPLE USAGE:\n",
    "    device='cpu'\n",
    "    model = MODEL() #a torch.nn.Module object \n",
    "    model.to(device)\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    x_test = np.ones((100,1,28,28),dtype=np.float32)\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "\n",
    "    NTK = calculate_NTK(model,x_test)\n",
    "    \"\"\"\n",
    "    if not(MODE in ['minima','samples','params']):\n",
    "        raise ValueError(\"MODE must be one of 'minima','samples','params'\")\n",
    "    \n",
    "    x = x.to(device)\n",
    "    x.requires_grad=False\n",
    "    N = x.shape[0]\n",
    "    M = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    #We need to create a clone of the model or else we make it unusable as part of the trickery \n",
    "    #to get pytorch to do what we want. Unforutantely, this exlcludes super big models. but, eh.\n",
    "    model_clone = copy.deepcopy(model)\n",
    "    \n",
    "    params, names = extract_weights(model_clone)\n",
    "    def model_ntk(*args,model=model_clone, names=names):\n",
    "        params = tuple(args)\n",
    "        load_weights(model, names, params)\n",
    "        return model(x)\n",
    "    \n",
    "    Js = torch.autograd.functional.jacobian(model_ntk, tuple(params), create_graph=False, vectorize=True)\n",
    "    \n",
    "    Js = list(Js)\n",
    "    #Js = [element for tupl in Js for element in tupl]\n",
    "    #collapse the tensors\n",
    "    for i,tensor in enumerate(Js):\n",
    "        Js[i] = tensor.reshape(N,-1)\n",
    "    \n",
    "    J = torch.cat(Js,axis=1)\n",
    "    \n",
    "    if MODE=='minima':\n",
    "        if N < M: #if datasize points is less than number of parameters:\n",
    "            NTK = torch.matmul(J,J.T)\n",
    "\n",
    "        if N >= M:#if number of parameters is less than datasize:\n",
    "            NTK = torch.matmul(J.T,J)\n",
    "    elif MODE=='samples':\n",
    "        NTK = torch.matmul(J,J.T)\n",
    "    elif MODE=='params':\n",
    "        NTK = torch.matmul(J.T,J)\n",
    "    \n",
    "    return NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d382e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def zero_pad(A,pad):\n",
    "    N, F, H, W = A.shape\n",
    "    P = np.zeros((N, F, H+2*pad, W+2*pad),dtype=np.float32)\n",
    "    P[:,:,pad:H+pad,pad:W+pad] = A\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6781cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calc_dw(x,w,b,pad,stride,H_,W_):\n",
    "    \"\"\"\n",
    "    Calculates the derivative of conv(x,w) with respect to w\n",
    "    \n",
    "    output is shape:\n",
    "        [datapoints, in_channels out_filters, kernel_height, kernel_width, out_filters, data_height, data_width\n",
    "    \n",
    "    'n f1 f2 c kh kw dh dw -> n (c f1 kh kw) (f2 dh dw)'\n",
    "    \"\"\"\n",
    "    dx, dw, db = None, None, None\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, HH, WW = w.shape\n",
    "    \n",
    "    #dw = np.zeros((N,F,F,C,HH,WW,H_,W_),dtype=np.float32)\n",
    "    \n",
    "    dw = np.zeros((N,C,F,HH,WW,F,H_,W_),dtype=np.float32)\n",
    "\n",
    "    xp = zero_pad(x,pad)\n",
    "    #high priority, how to vectorize this operation?\n",
    "    for n in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(HH): \n",
    "                for j in range(WW): \n",
    "                    for k in range(H_): \n",
    "                        for l in range(W_): \n",
    "                            for c in range(C): \n",
    "                                dw[n,c,f,i,j,f,k,l] += xp[n, c, i+stride*k, j+stride*l]                             \n",
    "    \n",
    "    return dw.reshape((N,(C*F*HH*WW),(F*H_*W_)))\n",
    "\n",
    "@njit\n",
    "def calc_dx(x,w,b,pad,stride,H_,W_):\n",
    "    '''\n",
    "    calculates the derivative of conv(x,w) with respect to x\n",
    "    \n",
    "    output is a nd-array of shape n x ch_in x og_h x og_w x (h_out w_out ch_out)\n",
    "    '''\n",
    "    dx, dw, db = None, None, None\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, HH, WW = w.shape \n",
    "\n",
    "    dx = np.zeros((C,H,W,F,H_,W_,),dtype=np.float32)\n",
    "    #high priority, how to vectorize this operation? maybe with np.chunk,split?\n",
    "    for f in range(F): \n",
    "        for i in range(H): \n",
    "            for j in range(W):\n",
    "                for k in range(H_): \n",
    "                    for l in range(W_):\n",
    "                        for c in range(C): \n",
    "                            if i-stride*k+pad > HH-1 or j-stride*l+pad > WW-1:\n",
    "                                continue #this is alternative to padding w with zeros.\n",
    "                            if i-stride*k+pad < 0 or j-stride*l+pad < 0:\n",
    "                                continue #this is alternative to padding w with zeros.\n",
    "                            dx[c,i,j,f,k,l] += w[f, c, i-stride*k+pad, j-stride*l+pad]\n",
    "    #'c ih iw f oh ow -> (c ih iw) (f oh ow)'\n",
    "    return dx.reshape(((C*H*W),(F*H_*W_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c19058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "#can I speed this up with chunks?\n",
    "#l=1\n",
    "#5.9ms vs 20.8 micro seconds; numba is taking care of the for loop vectorization for us.\n",
    "#for numpy this seems fine. \n",
    "#calc_dx(Xs[l].T,w=Ks[l],b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374c33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X,normalize=False):\n",
    "    X = F.relu(X)\n",
    "    if normalize:\n",
    "        return np.sqrt(2*np.pi/(np.pi-1))*(X-1/np.sqrt(2*np.pi))\n",
    "    else:\n",
    "        return X\n",
    "    \n",
    "\n",
    "# #Identity\n",
    "# def activation(x):\n",
    "#     return x\n",
    "\n",
    "# @njit\n",
    "# def d_activation(x):\n",
    "#     return np.ones(np.shape(x),dtype=np.float32) \n",
    "\n",
    "\n",
    "#Tanh\n",
    "def activation(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "@njit\n",
    "def d_activation(x):\n",
    "    return np.cosh(x)**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478cd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd2243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NTK_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bbef856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy NTK expects one output alone\n",
    "class dumb_small(torch.nn.Module):\n",
    "    '''\n",
    "    simple network for test cases\n",
    "    \n",
    "    \n",
    "    It seems like bias vectors aren't trivially added.\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Conv2d(1,4,3,bias=True)\n",
    "        \n",
    "        self.d2 = torch.nn.Conv2d(4,4,3,stride=2,padding=1,bias=True)\n",
    "\n",
    "        self.d3 = torch.nn.Conv2d(4,6,3,stride=1,padding=0,bias=True)\n",
    "        \n",
    "        self.d4 = torch.nn.Conv2d(6,8,3,stride=1,padding=0,bias=True)\n",
    "        \n",
    "        self.d5 = torch.nn.Conv2d(8,8,7,stride=1,padding=0,bias=True)\n",
    "        \n",
    "        self.d6 = torch.nn.Linear(3*3*8,16,bias=True)\n",
    "        \n",
    "        self.d7 = torch.nn.Linear(16,1,bias=True)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        x_5 = activation(self.d5(x_4))\n",
    "        x_6 = x_5.reshape(-1,3*3*8)\n",
    "        x_7 = activation(self.d6(x_6))\n",
    "        x_8 = self.d7(x_7)\n",
    "        return x_8\n",
    "    \n",
    "# Easy NTK expects one output alone\n",
    "class dumb_small_layerwise(torch.nn.Module):\n",
    "    '''\n",
    "    simple network for test cases\n",
    "    \n",
    "    \n",
    "    It seems like bias vectors aren't trivially added.\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small_layerwise, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Conv2d(1,4,3,bias=True)#28 -> 26\n",
    "\n",
    "        self.d2 = torch.nn.Conv2d(4,4,3,stride=2,padding=1,bias=True)#26 -> 13\n",
    "        \n",
    "        self.d3 = torch.nn.Conv2d(4,6,3,stride=1,padding=0,bias=True)#13 -> 11\n",
    "        \n",
    "        self.d4 = torch.nn.Conv2d(6,8,3,stride=1,padding=0,bias=True)#11 -> 9\n",
    "        \n",
    "        self.d5 = torch.nn.Conv2d(8,8,7,stride=1,padding=0,bias=True)#9 -> 3\n",
    "        \n",
    "        self.d6 = torch.nn.Linear(3*3*8,16,bias=True)\n",
    "        \n",
    "        self.d7 = torch.nn.Linear(16,1,bias=True)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        x_5 = activation(self.d5(x_4))\n",
    "        x_6 = x_5.reshape(-1,3*3*8)\n",
    "        x_7 = activation(self.d6(x_6))\n",
    "        x_8 = self.d7(x_7)\n",
    "        return x_8, x_7, x_6, x_5, x_4, x_3, x_2, x_1, x_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c1e57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3, 3])\n",
      "torch.Size([4, 4, 3, 3])\n",
      "torch.Size([6, 4, 3, 3])\n",
      "torch.Size([8, 6, 3, 3])\n",
      "torch.Size([8, 8, 7, 7])\n",
      "torch.Size([16, 72])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([4, 1, 3, 3])\n",
      "torch.Size([4, 4, 3, 3])\n",
      "torch.Size([6, 4, 3, 3])\n",
      "torch.Size([8, 6, 3, 3])\n",
      "torch.Size([8, 8, 7, 7])\n",
      "torch.Size([16, 72])\n",
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device='cpu'\n",
    "\n",
    "model_small = dumb_small()\n",
    "model_small.to(device)\n",
    "model_small.apply(NTK_weights)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device='cpu'\n",
    "\n",
    "model_layerwise = dumb_small_layerwise()\n",
    "model_layerwise.to(device)\n",
    "model_layerwise.apply(NTK_weights)\n",
    "\n",
    "x_test = np.random.normal(0,1,(300,1,28,28)).astype(np.float32) #n c_in, h, w\n",
    "x_test = torch.from_numpy(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52116a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(model_layerwise.d1.weight == model_small.d1.weight)\n",
    "assert torch.all(model_layerwise.d2.weight == model_small.d2.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7c321",
   "metadata": {},
   "source": [
    "# Easy_NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c13dfb34",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-69316112cbd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNTK_easy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_NTK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_small\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-9301a7867168>\u001b[0m in \u001b[0;36mcalculate_NTK\u001b[1;34m(model, x, device, MODE)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mJs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_ntk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mJs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[0;32m    548\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mjacobians_of_flat_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_vmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# Step 3: The returned jacobian is one big tensor per input. In this step,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\torch\\_vmap_internals.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mbatched_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_batched_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m             \u001b[0mbatched_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m             \u001b[0m_validate_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_unwrap_batched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mvjp\u001b[1;34m(grad_output)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[1;31m# Step 2: Call vmap + autograd.grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                 \u001b[0mvj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_autograd_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mel_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvj_el\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mvj_el\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, create_graph, retain_graph)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,\n\u001b[0m\u001b[0;32m    148\u001b[0m                                    create_graph=create_graph, retain_graph=retain_graph)\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#NTK_easy = calculate_NTK(model_small,x_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa16a2",
   "metadata": {},
   "source": [
    "# Pytorch Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4332263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small.zero_grad()\n",
    "y = model_small(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc96e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method agrees between model layerwise and model small; meaning that the calculation is indepdent of those\n",
    "#two models. the insinuation is somehting is wrong with both my methods for calculating,--- the same thing, since\n",
    "#they agree with one another.\n",
    "\n",
    "#in the future we would iterate over layers instead of like this...\n",
    "layer_components_w1 = [] \n",
    "layer_components_w2 = []\n",
    "layer_components_w3 = []\n",
    "layer_components_w4 = []\n",
    "layer_components_w5 = []\n",
    "layer_components_w6 = []\n",
    "layer_components_w7 = []\n",
    "\n",
    "layer_components_b1 = []\n",
    "layer_components_b2 = []\n",
    "layer_components_b3 = []\n",
    "layer_components_b4 = []\n",
    "layer_components_b5 = []\n",
    "layer_components_b6 = []\n",
    "layer_components_b7 = []\n",
    "\n",
    "for output in y:\n",
    "    model_small.zero_grad()\n",
    "    \n",
    "    output.backward(retain_graph=True)\n",
    "\n",
    "    #Get the tensors\n",
    "    w1_grad = model_small.d1.weight.grad.detach().numpy()\n",
    "    w2_grad = model_small.d2.weight.grad.detach().numpy()\n",
    "    w3_grad = model_small.d3.weight.grad.detach().numpy()\n",
    "    w4_grad = model_small.d4.weight.grad.detach().numpy()\n",
    "    w5_grad = model_small.d5.weight.grad.detach().numpy()\n",
    "    w6_grad = model_small.d6.weight.grad.detach().numpy()\n",
    "    w7_grad = model_small.d7.weight.grad.detach().numpy()\n",
    "    \n",
    "    b1_grad = model_small.d1.bias.grad.detach().numpy()\n",
    "    b2_grad = model_small.d2.bias.grad.detach().numpy()\n",
    "    b3_grad = model_small.d3.bias.grad.detach().numpy()\n",
    "    b4_grad = model_small.d4.bias.grad.detach().numpy()\n",
    "    b5_grad = model_small.d5.bias.grad.detach().numpy()\n",
    "    b6_grad = model_small.d6.bias.grad.detach().numpy()\n",
    "    b7_grad = model_small.d7.bias.grad.detach().numpy()\n",
    "\n",
    "    #reshape and append. deep copy neccessary or else they are the same objects\n",
    "    layer_components_w1.append(w1_grad.reshape(-1).copy())\n",
    "    layer_components_w2.append(w2_grad.reshape(-1).copy())\n",
    "    layer_components_w3.append(w3_grad.reshape(-1).copy())\n",
    "    layer_components_w4.append(w4_grad.reshape(-1).copy())\n",
    "    layer_components_w5.append(w5_grad.reshape(-1).copy())\n",
    "    layer_components_w6.append(w6_grad.reshape(-1).copy())\n",
    "    layer_components_w7.append(w7_grad.reshape(-1).copy())\n",
    "    \n",
    "    layer_components_b1.append(b1_grad.reshape(-1).copy())\n",
    "    layer_components_b2.append(b2_grad.reshape(-1).copy())\n",
    "    layer_components_b3.append(b3_grad.reshape(-1).copy())\n",
    "    layer_components_b4.append(b4_grad.reshape(-1).copy())\n",
    "    layer_components_b5.append(b5_grad.reshape(-1).copy())\n",
    "    layer_components_b6.append(b6_grad.reshape(-1).copy())\n",
    "    layer_components_b7.append(b7_grad.reshape(-1).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02228206",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_components_w1 = np.array(layer_components_w1)\n",
    "layer_components_w2 = np.array(layer_components_w2)\n",
    "layer_components_w3 = np.array(layer_components_w3)\n",
    "layer_components_w4 = np.array(layer_components_w4)\n",
    "layer_components_w5 = np.array(layer_components_w5)\n",
    "layer_components_w6 = np.array(layer_components_w6)\n",
    "layer_components_w7 = np.array(layer_components_w7)\n",
    "\n",
    "layer_components_b1 = np.array(layer_components_b1)\n",
    "layer_components_b2 = np.array(layer_components_b2)\n",
    "layer_components_b3 = np.array(layer_components_b3)\n",
    "layer_components_b4 = np.array(layer_components_b4)\n",
    "layer_components_b5 = np.array(layer_components_b5)\n",
    "layer_components_b6 = np.array(layer_components_b6)\n",
    "layer_components_b7 = np.array(layer_components_b7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df36c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "autograd_NTK = layer_components_w1 @ layer_components_w1.T+\\\n",
    "    layer_components_w2 @ layer_components_w2.T+\\\n",
    "    layer_components_w3 @ layer_components_w3.T+\\\n",
    "    layer_components_w4 @ layer_components_w4.T+\\\n",
    "    layer_components_w5 @ layer_components_w5.T+\\\n",
    "    layer_components_w6 @ layer_components_w6.T+\\\n",
    "    layer_components_w7 @ layer_components_w7.T+\\\n",
    "    layer_components_b1 @ layer_components_b1.T+\\\n",
    "    layer_components_b2 @ layer_components_b2.T+\\\n",
    "    layer_components_b3 @ layer_components_b3.T+\\\n",
    "    layer_components_b4 @ layer_components_b4.T+\\\n",
    "    layer_components_b5 @ layer_components_b5.T+\\\n",
    "    layer_components_b6 @ layer_components_b6.T+\\\n",
    "    layer_components_b7 @ layer_components_b7.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af204d12",
   "metadata": {},
   "source": [
    "# Layerwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdf5bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layerwise.to('cpu')\n",
    "x_8, x_7, x_6, x_5, x_4, x_3, x_2, x_1, x_0 = model_layerwise(x_test)\n",
    "\n",
    "#Dense Weight Matrices\n",
    "Ws = []\n",
    "Ws.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Ws.append(np.array([0.0],dtype=np.float32)) #spacer \n",
    "Ws.append(np.array([0.0],dtype=np.float32))\n",
    "Ws.append(np.array([0.0],dtype=np.float32))\n",
    "Ws.append(np.array([0.0],dtype=np.float32)) \n",
    "Ws.append(np.array([0.0],dtype=np.float32)) #spacer reshape is a layer\n",
    "Ws.append(model_layerwise.d6.weight.detach().numpy().astype(np.float32))\n",
    "Ws.append(model_layerwise.d7.weight.detach().numpy().astype(np.float32))\n",
    "\n",
    "Wspt = []\n",
    "Wspt.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Wspt.append(np.array([0.0],dtype=np.float32)) #spacer \n",
    "Wspt.append(np.array([0.0],dtype=np.float32))\n",
    "Wspt.append(np.array([0.0],dtype=np.float32))\n",
    "Wspt.append(np.array([0.0],dtype=np.float32)) \n",
    "Wspt.append(np.array([0.0],dtype=np.float32)) #spacer reshape is a layer\n",
    "Wspt.append(model_layerwise.d6.weight.detach())\n",
    "Wspt.append(model_layerwise.d7.weight.detach())\n",
    "\n",
    "\n",
    "#Kernel Matrices\n",
    "Ks = []\n",
    "Ks.append(model_layerwise.d1.weight.detach().numpy().astype(np.float32))\n",
    "Ks.append(model_layerwise.d2.weight.detach().numpy().astype(np.float32))\n",
    "Ks.append(model_layerwise.d3.weight.detach().numpy().astype(np.float32))\n",
    "Ks.append(model_layerwise.d4.weight.detach().numpy().astype(np.float32))\n",
    "Ks.append(model_layerwise.d5.weight.detach().numpy().astype(np.float32))\n",
    "Ks.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Ks.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Ks.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "\n",
    "Kspt = []\n",
    "Kspt.append(model_layerwise.d1.weight.detach())\n",
    "Kspt.append(model_layerwise.d2.weight.detach())\n",
    "Kspt.append(model_layerwise.d3.weight.detach())\n",
    "Kspt.append(model_layerwise.d4.weight.detach())\n",
    "Kspt.append(model_layerwise.d5.weight.detach())\n",
    "Kspt.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Kspt.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Kspt.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "\n",
    "# Xs = [] # Xs are shape (output x #DP) ; however, typical python notation is reversed, so we take transpose here\n",
    "# Xs.append(x_0.detach().numpy().T.astype(np.float32))\n",
    "# Xs.append(x_1.detach().numpy().T.astype(np.float32))\n",
    "# Xs.append(x_2.detach().numpy().T.astype(np.float32))\n",
    "# Xs.append(x_3.detach().numpy().T.astype(np.float32))\n",
    "# Xs.append(x_4.detach().numpy().T.astype(np.float32))\n",
    "# Xs.append(x_5.detach().numpy().T.astype(np.float32))\n",
    "# Xs.append(x_6.detach().numpy().T.astype(np.float32))\n",
    "# Xs.append(x_7.detach().numpy().T.astype(np.float32))\n",
    "\n",
    "Xs = [] # Xs are shape (output x #DP) ; however, typical python notation is reversed, so we take transpose here\n",
    "Xs.append(x_0.T.detach())\n",
    "Xs.append(x_1.T.detach())\n",
    "Xs.append(x_2.T.detach())\n",
    "Xs.append(x_3.T.detach())\n",
    "Xs.append(x_4.T.detach())\n",
    "Xs.append(x_5.T.detach())\n",
    "Xs.append(x_6.T.detach())\n",
    "Xs.append(x_7.T.detach())\n",
    "\n",
    "\n",
    "Bs = []\n",
    "Bs.append(model_layerwise.d1.bias.detach().numpy().astype(np.float32))\n",
    "Bs.append(model_layerwise.d2.bias.detach().numpy().astype(np.float32))\n",
    "Bs.append(model_layerwise.d3.bias.detach().numpy().astype(np.float32))\n",
    "Bs.append(model_layerwise.d4.bias.detach().numpy().astype(np.float32))\n",
    "Bs.append(model_layerwise.d5.bias.detach().numpy().astype(np.float32))\n",
    "Bs.append(np.array([0.0],dtype=np.float32))\n",
    "Bs.append(model_layerwise.d6.bias.detach().numpy().astype(np.float32)[:,None])\n",
    "Bs.append(model_layerwise.d7.bias.detach().numpy().astype(np.float32)[:,None])\n",
    "\n",
    "#This is used to create arrays-- needs to be integer list to play nice with compilers\n",
    "ds_int = []\n",
    "ds_int.append(0)\n",
    "ds_int.append(4*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(4*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(6*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(8*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(8*7*7) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(16) #number output features\n",
    "ds_int.append(1) #number output features\n",
    "\n",
    "ds_array = [] #this is for the NTK formulation, \n",
    "ds_array.append(np.array([1.0],dtype=np.float32)) #first element is a spacer, could be anything.\n",
    "ds_array.append(np.array([1.0],dtype=np.float32)) #The rest, even if you dont use NTK formulation, would be 1\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))\n",
    "\n",
    "padding = []\n",
    "padding.append(0)\n",
    "padding.append(1)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "\n",
    "strides = []\n",
    "strides.append(1)\n",
    "strides.append(2)\n",
    "strides.append(1)\n",
    "strides.append(1)\n",
    "strides.append(1)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "\n",
    "layers =[model_layerwise.d1,\n",
    "         model_layerwise.d2,\n",
    "         model_layerwise.d3,\n",
    "         model_layerwise.d4,\n",
    "         model_layerwise.d5,\n",
    "         0.0,\n",
    "         model_layerwise.d6,\n",
    "         model_layerwise.d7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b9fc6a",
   "metadata": {},
   "source": [
    "# Improve this algorithm's speed: here is the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fdf4b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def cross(X):\n",
    "    return X.T.dot(X)\n",
    "\n",
    "def cross_pt_nonp(X,device='cuda'):\n",
    "    X = X.to(device)\n",
    "    return X.T.matmul(X).cpu()\n",
    "\n",
    "def cross_pt(X,device='cuda'):\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "    X = X.to(device)\n",
    "    return X.T.matmul(X).cpu()\n",
    "\n",
    "def d_activationt(x):\n",
    "    return torch.cosh(x)**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85bebb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here are the updates we plan:\n",
    "def compute_NTK_CNN_w_Bias_oneshot(Ws, Ks, Xs, Bs, d_int, d_array, strides, padding, layers, device=\"cpu\"):\n",
    "    components = []\n",
    "    \n",
    "    L = len(Xs)-1 #number of layers, Xs goes from inputs to right before outputs; X_0 is the input, X_L CK\n",
    "    n = Xs[0].shape[-1] #number of datapoints\n",
    "\n",
    "    #holds the derivatives of activation, first value is empty list...?; just a spacer, replace with array\n",
    "    Ds_dense = [np.array([[0.0]],dtype=np.float32)] \n",
    "    Ds_conv = [np.array([[0.0]],dtype=np.float32)]\n",
    "    dws = []\n",
    "    dxs = []\n",
    "    s_matrices = []\n",
    "    with torch.no_grad():\n",
    "        ####################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Linear):\n",
    "                Ds_dense.append(d_activationt(layers[l](Xs[l].T)).T.numpy())\n",
    "            else:\n",
    "                Ds_dense.append(np.array([[0.0]],dtype=np.float32))\n",
    "        ################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Conv2d):\n",
    "                Ds_conv.append(d_activationt(layers[l](Xs[l].T)).numpy().reshape(n,-1).T)\n",
    "            else:\n",
    "                Ds_conv.append(np.array([[0.0]],dtype=np.float32))\n",
    "        ####################################################################################################        \n",
    "        for l in range(0,L):\n",
    "\n",
    "            if np.all(Ks[l]!=0):\n",
    "                dw = calc_dw(x=Xs[l].T.numpy(),w=Ks[l],b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                dws.append(dw)\n",
    "                if l != 0:\n",
    "                    dx = calc_dx(x=Xs[l].T.numpy(),w=Ks[l],b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                    dxs.append(dx[None,:,:])\n",
    "                else:\n",
    "                    dxs.append(np.array([[0.0]],dtype=np.float32))\n",
    "            else:\n",
    "                dws.append(np.array([[0.0]],dtype=np.float32))\n",
    "                dxs.append(np.array([[0.0]],dtype=np.float32))\n",
    "        \n",
    "        \n",
    "        ####################################################################################################\n",
    "        S = np.array([1.0],dtype=np.float32) #this models the backward propogation:   \n",
    "        for l in range(L,-1,-1):\n",
    "            #first we append the layers end to our component list\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "\n",
    "                components.append(cross_pt(S,device)*cross_pt_nonp(Xs[l],device))\n",
    "\n",
    "                W = np.multiply(np.ones((d_int[l],n),dtype=np.float32),S)\n",
    "                components.append(cross_pt(W,device))\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                if len(S.shape) == 2: #this should only affect the very last layer, at which point, who cares.\n",
    "                    S = S[None,:,:]\n",
    "                    \n",
    "                #s_matrices.append(S)\n",
    "                W = (torch.from_numpy(dws[l]).to(device) @ torch.from_numpy(S).to(device)).cpu().numpy()\n",
    "                #W = torch.matmul(dws[l].to_sparse(),torch.from_numpy(S).to(device)).cpu().numpy() \n",
    "                \n",
    "                #We should bring this to zhichao or sombody and ask if there is obviously something faster?\n",
    "                W = np.diagonal(W,0,2,0)\n",
    "\n",
    "                components.append(cross_pt(W,device))\n",
    "\n",
    "                N = Ks[l].shape[0]\n",
    "                W = np.split(S,N,axis=1)\n",
    "                W = np.array(W)\n",
    "                W = np.sum(W,axis=(1,2))\n",
    "                components.append(cross_pt(W,device))\n",
    "\n",
    "            #############################\n",
    "            #now we setup S for the next loop by treating appropriately\n",
    "            if l==0:\n",
    "                break\n",
    "\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                S = np.dot(S.T,Ws[l]).T/np.sqrt(d_array[l])\n",
    "                if len(S.shape) < 2:\n",
    "                    S = S[:,None] #expand dimension along axis 1\n",
    "                if not(isinstance(layers[l-1],float)): #this exludes the reshaping layer\n",
    "                    S = Ds_dense[l]*S\n",
    "                else: #and when the reshaping layer occurs we need to apply this instead\n",
    "                    S = Ds_conv[l-1]*S\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                S = (dxs[l] @ S) / np.sqrt(d_array[l])\n",
    "                S = Ds_conv[l]*S\n",
    "            \n",
    "    return components#, dws, s_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e20b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here are the updates we plan:\n",
    "def compute_NTK_CNN_w_Bias_oneshot_asneeded(Ws, Ks, Xs, Bs, d_int, d_array, strides, padding, layers, device=\"cpu\"):\n",
    "    components = []\n",
    "    \n",
    "    L = len(Xs)-1 #number of layers, Xs goes from inputs to right before outputs; X_0 is the input, X_L CK\n",
    "    n = Xs[0].shape[-1] #number of datapoints\n",
    "\n",
    "    #holds the derivatives of activation, first value is empty list...?; just a spacer, replace with array\n",
    "    Ds_dense = [np.array([[0.0]],dtype=np.float32)] \n",
    "    Ds_conv = [np.array([[0.0]],dtype=np.float32)]\n",
    "    s_matrices = []\n",
    "    with torch.no_grad():\n",
    "        ####################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Linear):\n",
    "                Ds_dense.append(d_activationt(layers[l](Xs[l].T)).T.numpy())\n",
    "            else:\n",
    "                Ds_dense.append(np.array([[0.0]],dtype=np.float32))\n",
    "        ################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Conv2d):\n",
    "                Ds_conv.append(d_activationt(layers[l](Xs[l].T)).numpy().reshape(n,-1).T)\n",
    "            else:\n",
    "                Ds_conv.append(np.array([[0.0]],dtype=np.float32))      \n",
    "        ####################################################################################################\n",
    "        S = np.array([1.0],dtype=np.float32) #this models the backward propogation:   \n",
    "        for l in range(L,-1,-1):\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "\n",
    "                components.append(cross_pt(S,device)*cross_pt_nonp(Xs[l],device))\n",
    "\n",
    "                W = np.multiply(np.ones((d_int[l],n),dtype=np.float32),S)\n",
    "                components.append(cross_pt(W,device))\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                if len(S.shape) == 2: #this should only affect the very last layer, at which point, who cares.\n",
    "                    S = S[None,:,:]\n",
    "                    \n",
    "                dw = calc_dw(x=Xs[l].T.numpy(),w=Ks[l],b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                W = (torch.from_numpy(dw).to(device) @ torch.from_numpy(S).to(device)).cpu().numpy()\n",
    "                \n",
    "                #We should bring this to zhichao or sombody and ask if there is obviously something faster?\n",
    "                W = np.diagonal(W,0,2,0)\n",
    "\n",
    "                components.append(cross_pt(W,device))\n",
    "\n",
    "                N = Ks[l].shape[0]\n",
    "                W = np.split(S,N,axis=1)\n",
    "                W = np.array(W)\n",
    "                W = np.sum(W,axis=(1,2))\n",
    "                components.append(cross_pt(W,device))\n",
    "\n",
    "            #############################\n",
    "            #now we setup S for the next loop by treating appropriately\n",
    "            if l==0:\n",
    "                break\n",
    "\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                S = np.dot(S.T,Ws[l]).T/np.sqrt(d_array[l])\n",
    "                if len(S.shape) < 2:\n",
    "                    S = S[:,None] #expand dimension along axis 1\n",
    "                if not(isinstance(layers[l-1],float)): #this exludes the reshaping layer\n",
    "                    S = Ds_dense[l]*S\n",
    "                else: #and when the reshaping layer occurs we need to apply this instead\n",
    "                    S = Ds_conv[l-1]*S\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                dx = calc_dx(x=Xs[l].T.numpy(),w=Ks[l],b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                S = (dx[None,:,:] @ S) / np.sqrt(d_array[l])\n",
    "                S = Ds_conv[l]*S\n",
    "            \n",
    "    return components#, dws, s_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de80272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here are the updates we plan:\n",
    "def compute_NTK_CNN_w_Bias_oneshot_PT(Ws, Ks, Xs, Bs, d_int, d_array, strides, padding, layers, device=\"cpu\"):\n",
    "    components = []\n",
    "    \n",
    "    L = len(Xs)-1 #number of layers, Xs goes from inputs to right before outputs; X_0 is the input, X_L CK\n",
    "    n = Xs[0].shape[-1] #number of datapoints\n",
    "\n",
    "    #holds the derivatives of activation, first value is empty list...?; just a spacer, replace with array\n",
    "    Ds_dense = [np.array([[0.0]],dtype=np.float32)] \n",
    "    Ds_conv = [np.array([[0.0]],dtype=np.float32)]\n",
    "    s_matrices = []\n",
    "    with torch.no_grad():\n",
    "        ####################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Linear):\n",
    "                Ds_dense.append(d_activationt(layers[l](Xs[l].T)).T)\n",
    "            else:\n",
    "                Ds_dense.append(np.array([[0.0]],dtype=np.float32))\n",
    "        ################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Conv2d):\n",
    "                Ds_conv.append(d_activationt(layers[l](Xs[l].T)).reshape(n,-1).T)\n",
    "            else:\n",
    "                Ds_conv.append(np.array([[0.0]],dtype=np.float32))      \n",
    "        ####################################################################################################\n",
    "        S = torch.tensor([1.0],dtype=torch.float32) #this models the backward propogation:   \n",
    "        for l in range(L,-1,-1):\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "\n",
    "                components.append(cross_pt_nonp(S,device)*cross_pt_nonp(Xs[l],device))\n",
    "\n",
    "                W = torch.ones((d_int[l],n),dtype=torch.float32) * S\n",
    "                components.append(cross_pt_nonp(W,device))\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                if len(S.shape) == 2: #this should only affect the very last layer, at which point, who cares.\n",
    "                    S = S[None,:,:]\n",
    "                    \n",
    "                dw = calc_dw(x=Xs[l].T.numpy(),w=Ks[l].numpy(),b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                \n",
    "                W = torch.matmul(torch.from_numpy(dw).to(device),S.to(device)).cpu()\n",
    "                \n",
    "                #We should bring this to zhichao or sombody and ask if there is obviously something faster?\n",
    "                #W = np.diagonal(W,0,2,0)\n",
    "                W = torch.diagonal(W,0,0,2)\n",
    "\n",
    "                components.append(cross_pt_nonp(W,device))\n",
    "\n",
    "                N = Ks[l].shape[0]\n",
    "                #W = np.split(S,N,axis=1)\n",
    "                W = torch.split(S,N,dim=1)\n",
    "                \n",
    "                #W = np.array(W)\n",
    "                W = torch.stack(W)\n",
    "                \n",
    "                #W = np.sum(W,axis=(1,2))\n",
    "                W = torch.sum(W,dim=(1,2))\n",
    "\n",
    "                components.append(cross_pt_nonp(W,device))\n",
    "\n",
    "            #############################\n",
    "            #now we setup S for the next loop by treating appropriately\n",
    "            if l==0:\n",
    "                break\n",
    "\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                #S = np.dot(S.T,Ws[l]).T/np.sqrt(d_array[l])\n",
    "                S = torch.matmul(S.T,Ws[l]) / np.sqrt(d_array[l])\n",
    "                if len(S.shape) < 2:\n",
    "                    S = S[:,None] #expand dimension along axis 1\n",
    "                if not(isinstance(layers[l-1],float)): #this exludes the reshaping layer\n",
    "                    S = Ds_dense[l]*S\n",
    "                else: #and when the reshaping layer occurs we need to apply this instead\n",
    "                    S = Ds_conv[l-1]*S.T\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                dx = calc_dx(x=Xs[l].T.numpy(),w=Ks[l].numpy(),b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                S = (torch.from_numpy(dx[None,:,:]) @ S) / np.sqrt(d_array[l])\n",
    "                S = Ds_conv[l]*S\n",
    "            \n",
    "    return components#, dws, s_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8930bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "49b7beba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15 s  22.8 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "components = compute_NTK_CNN_w_Bias_oneshot_asneeded(Wspt, Kspt, Xs, Bs, ds_int, ds_array, strides, padding, layers, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe42f52a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_NTK_CNN_w_Bias_PT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-0760d2cb0df2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lprun'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-f compute_NTK_CNN_w_Bias_oneshot_PT compute_NTK_CNN_w_Bias_PT(Ws, Ks, Xs, Bs, ds_int, ds_array, strides, padding, layers, device=\"cuda\")'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2342\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2343\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2344\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2345\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\line_profiler\\line_profiler.py\u001b[0m in \u001b[0;36mlprun\u001b[1;34m(self, parameter_s)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                 \u001b[0mprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_ns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m                 \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\line_profiler\\line_profiler.py\u001b[0m in \u001b[0;36mrunctx\u001b[1;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_by_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             \u001b[0mexec_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_by_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_NTK_CNN_w_Bias_PT' is not defined"
     ]
    }
   ],
   "source": [
    "%lprun -f compute_NTK_CNN_w_Bias_oneshot_PT compute_NTK_CNN_w_Bias_PT(Ws, Ks, Xs, Bs, ds_int, ds_array, strides, padding, layers, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b26b0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.94 is fast compared to the time of easy_ntk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6659b14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5179"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model_layerwise.parameters() if p.requires_grad)\n",
    "#lol yikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465fcc6",
   "metadata": {},
   "source": [
    "# Compare Against One another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89bc772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enge625\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\enge625\\Miniconda3\\envs\\pytorch1.9\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.3348228e+05,  2.5838447e+03, -5.5709082e+03, ...,\n",
       "         1.5912437e+03, -8.4559541e+03, -1.3930099e+02],\n",
       "       [ 2.5838447e+03,  1.3920228e+03,  5.7449066e+01, ...,\n",
       "        -1.6074094e+03, -2.0567888e+02,  6.2342400e+01],\n",
       "       [-5.5709082e+03,  5.7449066e+01,  2.4104357e+04, ...,\n",
       "        -4.5882139e+03,  8.9728925e+02,  2.1850346e+01],\n",
       "       ...,\n",
       "       [ 1.5912437e+03, -1.6074094e+03, -4.5882139e+03, ...,\n",
       "         5.2759320e+04, -1.9727719e+03, -1.2601754e+03],\n",
       "       [-8.4559541e+03, -2.0567888e+02,  8.9728925e+02, ...,\n",
       "        -1.9727719e+03,  5.9253203e+03,  5.6632980e+01],\n",
       "       [-1.3930099e+02,  6.2342400e+01,  2.1850346e+01, ...,\n",
       "        -1.2601754e+03,  5.6632980e+01,  4.5298846e+02]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTK_layerwise = np.sum(components)\n",
    "NTK_layerwise.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fb7fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3348217e+05,  2.5838464e+03, -5.5709131e+03],\n",
       "       [ 2.5838467e+03,  1.3920264e+03,  5.7448795e+01],\n",
       "       [-5.5709131e+03,  5.7448689e+01,  2.4104338e+04]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTK_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82286a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3348231e+05,  2.5838425e+03, -5.5709087e+03, ...,\n",
       "         1.5912489e+03, -8.4559551e+03, -1.3929858e+02],\n",
       "       [ 2.5838425e+03,  1.3920225e+03,  5.7448956e+01, ...,\n",
       "        -1.6074094e+03, -2.0567831e+02,  6.2342556e+01],\n",
       "       [-5.5709087e+03,  5.7448956e+01,  2.4104354e+04, ...,\n",
       "        -4.5882158e+03,  8.9729010e+02,  2.1850412e+01],\n",
       "       ...,\n",
       "       [ 1.5912489e+03, -1.6074094e+03, -4.5882158e+03, ...,\n",
       "         5.2759348e+04, -1.9727728e+03, -1.2601753e+03],\n",
       "       [-8.4559551e+03, -2.0567831e+02,  8.9729010e+02, ...,\n",
       "        -1.9727728e+03,  5.9253208e+03,  5.6632790e+01],\n",
       "       [-1.3929858e+02,  6.2342556e+01,  2.1850412e+01, ...,\n",
       "        -1.2601753e+03,  5.6632790e+01,  4.5298849e+02]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd_NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76046bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NTK_easy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-9d2ce979de0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(np.allclose(NTK_layerwise.cpu().detach().numpy(),NTK_easy))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNTK_layerwise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautograd_NTK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNTK_easy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautograd_NTK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'NTK_easy' is not defined"
     ]
    }
   ],
   "source": [
    "#print(np.allclose(NTK_layerwise.cpu().detach().numpy(),NTK_easy))\n",
    "print(np.allclose(NTK_layerwise.detach().numpy(),autograd_NTK,rtol=1e-1))\n",
    "print(np.allclose(NTK_easy,autograd_NTK))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270825e",
   "metadata": {},
   "source": [
    "# Compare Layerwise Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "824ca5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.8464969e+04  2.6263931e+03 -4.8651577e+03 ...  3.5916440e+03\n",
      "  -8.4994512e+03  1.2480615e+02]\n",
      " [ 2.6263931e+03  6.2154340e+02  1.0863655e+02 ... -7.7489374e+02\n",
      "  -9.8777687e+01  2.6040871e+01]\n",
      " [-4.8651577e+03  1.0863655e+02  1.3723626e+04 ... -1.9260972e+03\n",
      "   9.8088300e+02 -1.0505713e+02]\n",
      " ...\n",
      " [ 3.5916440e+03 -7.7489374e+02 -1.9260972e+03 ...  2.2143219e+04\n",
      "  -1.8547600e+03 -8.4317175e+02]\n",
      " [-8.4994512e+03 -9.8777687e+01  9.8088300e+02 ... -1.8547600e+03\n",
      "   3.2994490e+03  1.0212484e+02]\n",
      " [ 1.2480615e+02  2.6040871e+01 -1.0505713e+02 ... -8.4317175e+02\n",
      "   1.0212484e+02  2.4311635e+02]]\n",
      "[[ 2.47159922e+04  1.38156631e+02 -6.25420593e+02 ... -1.28638721e+03\n",
      "  -7.23600220e+02  1.76240921e+01]\n",
      " [ 1.38156631e+02  3.16876068e+02 -1.24793434e+02 ... -6.39673706e+02\n",
      "   2.79912357e+01 -1.93850374e+00]\n",
      " [-6.25420593e+02 -1.24793434e+02  4.95354688e+03 ...  7.54058350e+02\n",
      "  -2.47659531e+02  1.74559002e+01]\n",
      " ...\n",
      " [-1.28638721e+03 -6.39673706e+02  7.54058350e+02 ...  1.74292520e+04\n",
      "  -1.32594360e+02 -2.59377838e+02]\n",
      " [-7.23600220e+02  2.79912357e+01 -2.47659531e+02 ... -1.32594360e+02\n",
      "   1.39361084e+03 -1.99681435e+01]\n",
      " [ 1.76240921e+01 -1.93850374e+00  1.74559002e+01 ... -2.59377838e+02\n",
      "  -1.99681435e+01  1.02348427e+02]]\n",
      "[[ 1.06726455e+04  1.44796768e+02  5.01990051e+02 ...  4.26413422e+01\n",
      "   4.66183716e+02 -3.66260490e+01]\n",
      " [ 1.44796768e+02  2.28937302e+02  2.95191021e+01 ... -9.51628571e+01\n",
      "  -5.40658722e+01 -3.52256227e+00]\n",
      " [ 5.01990051e+02  2.95191021e+01  2.25302173e+03 ...  5.54872284e+01\n",
      "   1.34175629e+02 -2.31191063e+00]\n",
      " ...\n",
      " [ 4.26413422e+01 -9.51628571e+01  5.54872284e+01 ...  4.99394482e+03\n",
      "   8.17910461e+01 -3.12033119e+01]\n",
      " [ 4.66183716e+02 -5.40658722e+01  1.34175629e+02 ...  8.17910461e+01\n",
      "   7.89322998e+02  2.17138362e+00]\n",
      " [-3.66260490e+01 -3.52256227e+00 -2.31191063e+00 ... -3.12033119e+01\n",
      "   2.17138362e+00  4.32600899e+01]]\n",
      "[[ 2.99031885e+03  7.70762730e+00  6.38075409e+01 ... -2.13095490e+02\n",
      "  -4.86535416e+01 -3.28437662e+00]\n",
      " [ 7.70762730e+00  5.56665001e+01 -1.86814251e+01 ... -1.24881077e+01\n",
      "  -4.94960880e+00 -1.36203027e+00]\n",
      " [ 6.38075409e+01 -1.86814251e+01  5.12237427e+02 ... -3.37170601e+01\n",
      "  -1.31761055e+01  6.47433758e-01]\n",
      " ...\n",
      " [-2.13095490e+02 -1.24881077e+01 -3.37170601e+01 ...  1.02425720e+03\n",
      "   2.18924260e+00 -1.98265576e+00]\n",
      " [-4.86535416e+01 -4.94960880e+00 -1.31761055e+01 ...  2.18924260e+00\n",
      "   1.75513916e+02 -1.12184620e+00]\n",
      " [-3.28437662e+00 -1.36203027e+00  6.47433758e-01 ... -1.98265576e+00\n",
      "  -1.12184620e+00  7.63436508e+00]]\n",
      "[[ 7.65340332e+02 -4.70892096e+00  1.46631241e+00 ...  1.52383690e+01\n",
      "  -3.93415356e+00 -8.31384897e-01]\n",
      " [-4.70892096e+00  1.26478577e+01  1.61306095e+00 ...  1.07434809e+00\n",
      "   4.03982222e-01 -8.18953104e-03]\n",
      " [ 1.46631241e+00  1.61306095e+00  1.02333206e+02 ...  2.21823907e+00\n",
      "   9.97964025e-01 -1.14973176e+00]\n",
      " ...\n",
      " [ 1.52383690e+01  1.07434809e+00  2.21823907e+00 ...  3.99761627e+02\n",
      "   4.32966089e+00 -1.11550963e+00]\n",
      " [-3.93415356e+00  4.03982222e-01  9.97964025e-01 ...  4.32966089e+00\n",
      "   3.26291084e+01 -2.18519598e-01]\n",
      " [-8.31384897e-01 -8.18953104e-03 -1.14973176e+00 ... -1.11550963e+00\n",
      "  -2.18519598e-01  2.14445639e+00]]\n",
      "[[ 5.5415596e+01 -2.5942707e-05  1.0585098e+00 ...  9.4544208e-01\n",
      "  -1.6446246e-01  2.4375748e-03]\n",
      " [-2.5942707e-05  2.2392210e+01  7.2571624e-05 ...  7.1344740e-04\n",
      "   5.6088254e-07  6.0685333e-02]\n",
      " [ 1.0585098e+00  7.2571624e-05  8.2840452e+00 ...  1.2443804e+00\n",
      "   9.5339224e-04  2.4031663e-02]\n",
      " ...\n",
      " [ 9.4544208e-01  7.1344740e-04  1.2443804e+00 ...  2.5198906e+01\n",
      "   1.1614069e+00  3.4580287e-02]\n",
      " [-1.6446246e-01  5.6088254e-07  9.5339224e-04 ...  1.1614069e+00\n",
      "   5.8471708e+00  5.6834286e-04]\n",
      " [ 2.4375748e-03  6.0685333e-02  2.4031663e-02 ...  3.4580287e-02\n",
      "   5.6834286e-04  1.8657506e+00]]\n",
      "[[13.446263    2.924193    0.24827147 ... -2.1980977   4.0170503\n",
      "  -4.626627  ]\n",
      " [ 2.924193   15.294244   -1.0446327  ... -3.4332037   0.47205245\n",
      "   0.4640553 ]\n",
      " [ 0.24827147 -1.0446327  14.927135   ...  5.2288723   2.2044697\n",
      "   5.196067  ]\n",
      " ...\n",
      " [-2.1980977  -3.4332037   5.2288723  ... 14.383441    7.323278\n",
      "   0.7400056 ]\n",
      " [ 4.0170503   0.47205245  2.2044697  ...  7.323278   14.679657\n",
      "  -0.47891778]\n",
      " [-4.626627    0.4640553   5.196067   ...  0.7400056  -0.47891778\n",
      "  15.253405  ]]\n",
      " \n",
      "[[ 5128.149     -269.06732   -624.46906  ...  -798.0781     257.0728\n",
      "   -225.65042 ]\n",
      " [ -269.06732     89.592865    72.18403  ...    59.186928   -55.994614\n",
      "     36.691055]\n",
      " [ -624.46906     72.18403   2307.8955   ... -3193.9644     -65.66832\n",
      "     79.040794]\n",
      " ...\n",
      " [ -798.0781      59.186928 -3193.9644   ...  5171.1973      36.469856\n",
      "    -51.163483]\n",
      " [  257.0728     -55.994614   -65.66832  ...    36.469856    76.274345\n",
      "    -45.419495]\n",
      " [ -225.65042     36.691055    79.040794 ...   -51.163483   -45.419495\n",
      "     28.840366]]\n",
      "[[ 222.69144    -43.171825   -68.04991   ...  246.46344     28.605656\n",
      "   -12.720696 ]\n",
      " [ -43.171825    18.459694     1.8041105 ... -128.47247    -10.514439\n",
      "     2.5938656]\n",
      " [ -68.04991      1.8041105  173.38611   ... -210.18579     91.55266\n",
      "    26.417318 ]\n",
      " ...\n",
      " [ 246.46344   -128.47247   -210.18579   ... 1390.875     -146.31837\n",
      "   -64.41211  ]\n",
      " [  28.605656   -10.514439    91.55266   ... -146.31837    109.12865\n",
      "    21.272175 ]\n",
      " [ -12.720696     2.5938656   26.417318  ...  -64.41211     21.272175\n",
      "     5.8962603]]\n",
      "[[ 4.1327060e+02 -2.0780754e+01  3.5679104e+01 ...  7.1318398e+00\n",
      "   5.8689606e+01  2.6246715e+00]\n",
      " [-2.0780754e+01  8.7710037e+00 -1.1047936e+01 ... -1.4201223e+01\n",
      "  -1.1042200e+01  2.3428848e+00]\n",
      " [ 3.5679104e+01 -1.1047936e+01  3.9433025e+01 ... -2.9375227e+01\n",
      "   1.1603932e+01  2.9026261e-01]\n",
      " ...\n",
      " [ 7.1318398e+00 -1.4201223e+01 -2.9375227e+01 ...  1.2723113e+02\n",
      "   2.7036552e+01 -8.8255835e+00]\n",
      " [ 5.8689606e+01 -1.1042200e+01  1.1603932e+01 ...  2.7036552e+01\n",
      "   2.4247831e+01 -2.2692797e+00]\n",
      " [ 2.6246715e+00  2.3428848e+00  2.9026261e-01 ... -8.8255835e+00\n",
      "  -2.2692797e+00  1.3939891e+00]]\n",
      "[[ 3.6115330e+01  7.5542408e-01  6.8234534e+00 ... -1.4863115e+01\n",
      "   4.0415525e+00 -1.5827523e+00]\n",
      " [ 7.5542408e-01  4.9633151e-01 -1.7502015e+00 ... -3.6372173e-01\n",
      "  -2.1695055e-01 -2.6935276e-02]\n",
      " [ 6.8234534e+00 -1.7502015e+00  1.4245322e+01 ... -1.4278033e+01\n",
      "   1.3501353e+00  3.0603141e-01]\n",
      " ...\n",
      " [-1.4863115e+01 -3.6372173e-01 -1.4278033e+01 ...  3.7544067e+01\n",
      "  -5.5995393e-01 -6.5832067e-01]\n",
      " [ 4.0415525e+00 -2.1695055e-01  1.3501353e+00 ... -5.5995393e-01\n",
      "   3.4619365e+00 -4.5421124e-01]\n",
      " [-1.5827523e+00 -2.6935276e-02  3.0603141e-01 ... -6.5832067e-01\n",
      "  -4.5421124e-01  2.0442936e-01]]\n",
      "[[ 2.15847158e+00 -1.62126467e-01  4.98102531e-02 ...  5.57373405e-01\n",
      "   1.53159853e-02 -3.39937769e-02]\n",
      " [-1.62126467e-01  2.59366967e-02  9.36906319e-03 ...  1.73960607e-02\n",
      "   1.58048794e-02  9.38187120e-04]\n",
      " [ 4.98102531e-02  9.36906319e-03  2.95731008e-01 ...  5.14844917e-02\n",
      "   2.52131689e-02 -1.09512601e-02]\n",
      " ...\n",
      " [ 5.57373405e-01  1.73960607e-02  5.14844917e-02 ...  1.12635040e+00\n",
      "   1.06976606e-01 -4.45591398e-02]\n",
      " [ 1.53159853e-02  1.58048794e-02  2.52131689e-02 ...  1.06976606e-01\n",
      "   6.82177991e-02 -5.83196897e-03]\n",
      " [-3.39937769e-02  9.38187120e-04 -1.09512601e-02 ... -4.45591398e-02\n",
      "  -5.83196897e-03  3.93565232e-03]]\n",
      "[[8.1088394e-01 7.7931163e-06 6.5560080e-02 ... 2.4907672e-01\n",
      "  2.2232406e-01 3.8599712e-04]\n",
      " [7.7931163e-06 3.1927490e-01 2.9915076e-04 ... 1.3502104e-04\n",
      "  4.6602572e-06 6.4196009e-03]\n",
      " [6.5560080e-02 2.9915076e-04 1.2048086e-01 ... 1.1333607e-01\n",
      "  7.8863566e-05 2.3005868e-03]\n",
      " ...\n",
      " [2.4907672e-01 1.3502104e-04 1.1333607e-01 ... 3.6381537e-01\n",
      "  5.1983975e-02 5.2218996e-03]\n",
      " [2.2232406e-01 4.6602572e-06 7.8863566e-05 ... 5.1983975e-02\n",
      "  8.7163374e-02 8.1916332e-05]\n",
      " [3.8599712e-04 6.4196009e-03 2.3005868e-03 ... 5.2218996e-03\n",
      "  8.1916332e-05 2.6620207e-02]]\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(layer_components_w1 @ layer_components_w1.T)\n",
    "print(layer_components_w2 @ layer_components_w2.T)\n",
    "print(layer_components_w3 @ layer_components_w3.T)\n",
    "print(layer_components_w4 @ layer_components_w4.T)\n",
    "print(layer_components_w5 @ layer_components_w5.T)\n",
    "print(layer_components_w6 @ layer_components_w6.T)\n",
    "print(layer_components_w7 @ layer_components_w7.T)\n",
    "print(' ')\n",
    "print(layer_components_b1 @ layer_components_b1.T)\n",
    "print(layer_components_b2 @ layer_components_b2.T)\n",
    "print(layer_components_b3 @ layer_components_b3.T)\n",
    "print(layer_components_b4 @ layer_components_b4.T)\n",
    "print(layer_components_b5 @ layer_components_b5.T)\n",
    "print(layer_components_b6 @ layer_components_b6.T)\n",
    "print(layer_components_b7 @ layer_components_b7.T)\n",
    "\n",
    "NTK_components_autograd = [\n",
    "    layer_components_w7 @ layer_components_w7.T,\n",
    "    layer_components_b7 @ layer_components_b7.T,\n",
    "    layer_components_w6 @ layer_components_w6.T,\n",
    "    layer_components_b6 @ layer_components_b6.T,\n",
    "    layer_components_w5 @ layer_components_w5.T,\n",
    "    layer_components_b5 @ layer_components_b5.T,\n",
    "    layer_components_w4 @ layer_components_w4.T,\n",
    "    layer_components_b4 @ layer_components_b4.T,\n",
    "    layer_components_w3 @ layer_components_w3.T,\n",
    "    layer_components_b3 @ layer_components_b3.T,\n",
    "    layer_components_w2 @ layer_components_w2.T,\n",
    "    layer_components_b2 @ layer_components_b2.T,\n",
    "    layer_components_w1 @ layer_components_w1.T,\n",
    "    layer_components_b1 @ layer_components_b1.T,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5447b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[ 2.99031885e+03  7.70762730e+00  6.38075409e+01 ... -2.13095490e+02\n",
      "  -4.86535416e+01 -3.28437662e+00]\n",
      " [ 7.70762730e+00  5.56665001e+01 -1.86814251e+01 ... -1.24881077e+01\n",
      "  -4.94960880e+00 -1.36203027e+00]\n",
      " [ 6.38075409e+01 -1.86814251e+01  5.12237427e+02 ... -3.37170601e+01\n",
      "  -1.31761055e+01  6.47433758e-01]\n",
      " ...\n",
      " [-2.13095490e+02 -1.24881077e+01 -3.37170601e+01 ...  1.02425720e+03\n",
      "   2.18924260e+00 -1.98265576e+00]\n",
      " [-4.86535416e+01 -4.94960880e+00 -1.31761055e+01 ...  2.18924260e+00\n",
      "   1.75513916e+02 -1.12184620e+00]\n",
      " [-3.28437662e+00 -1.36203027e+00  6.47433758e-01 ... -1.98265576e+00\n",
      "  -1.12184620e+00  7.63436508e+00]]\n",
      "tensor([[ 2.9903e+03,  7.7076e+00,  6.3808e+01,  ..., -2.1310e+02,\n",
      "         -4.8654e+01, -3.2844e+00],\n",
      "        [ 7.7076e+00,  5.5667e+01, -1.8681e+01,  ..., -1.2488e+01,\n",
      "         -4.9496e+00, -1.3620e+00],\n",
      "        [ 6.3808e+01, -1.8681e+01,  5.1224e+02,  ..., -3.3717e+01,\n",
      "         -1.3176e+01,  6.4744e-01],\n",
      "        ...,\n",
      "        [-2.1310e+02, -1.2488e+01, -3.3717e+01,  ...,  1.0243e+03,\n",
      "          2.1893e+00, -1.9827e+00],\n",
      "        [-4.8654e+01, -4.9496e+00, -1.3176e+01,  ...,  2.1893e+00,\n",
      "          1.7551e+02, -1.1218e+00],\n",
      "        [-3.2844e+00, -1.3620e+00,  6.4744e-01,  ..., -1.9827e+00,\n",
      "         -1.1218e+00,  7.6344e+00]])\n"
     ]
    }
   ],
   "source": [
    "l = 6\n",
    "\n",
    "print(np.allclose(NTK_components_autograd[l],components[l],1e-1))\n",
    "\n",
    "print(NTK_components_autograd[l])\n",
    "print(components[l])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
